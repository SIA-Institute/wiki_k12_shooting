{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build port "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    url='https://en.wikipedia.org/wiki/List_of_school_shootings_in_the_United_States'\n",
    ")\n",
    "print(response.status_code) # should be 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Table Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "      url='https://en.wikipedia.org/wiki/List_of_school_shootings_in_the_United_States'\n",
    "#     url =r'https://en.wikipedia.org/wiki/List_of_school_shootings_in_the_United_States_(before_2000)'\n",
    ")\n",
    "print(response.status_code) # should be 200\n",
    "\n",
    "soup = BeautifulSoup(response.text,'lxml')\n",
    "\n",
    "# extract pure data \n",
    "data = []\n",
    "colum_names = []\n",
    "# find all sortabel tables\n",
    "for i in soup.find_all(name='table'):\n",
    "    \n",
    "    # find all column names \n",
    "    for j in i.find_all(name='th'):\n",
    "        colum_names.append(j.text.rstrip())\n",
    "    \n",
    "    # find each row\n",
    "    for k in i.find_all(name='tr'):\n",
    "        \n",
    "        each_row ={}\n",
    "        # each item in the row\n",
    "        for index,item in enumerate(k.find_all(name='td')):\n",
    "            each_row[colum_names[index]] = item.text.rstrip()\n",
    "        \n",
    "        data.append(each_row)\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.dropna(axis=0).reset_index(drop=True) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scrapping Latitude and Longitude of citys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "loc_href = []\n",
    "for i in soup.find_all(name='table',attrs={'class':'sortable wikitable'}):\n",
    "    for j in i.find_all(name='tr'):\n",
    "        \n",
    "        each_row ={}\n",
    "        iter_ = iter(j.find_all('td'))\n",
    "        while True:\n",
    "            try:\n",
    "                each_row['Date']=next(iter_).text.rstrip()\n",
    "                loc = next(iter_)\n",
    "                each_row['Location']=loc.text.rstrip()\n",
    "                # find latitude and logitude\n",
    "                re_loc = requests.get(\n",
    "                    url='https://en.wikipedia.org{}'.format(loc.a['href'])\n",
    "                )\n",
    "\n",
    "                bs = BeautifulSoup(re_loc.text,'lxml')\n",
    "                b = bs.find('span',attrs={'class':'plainlinks nourlexpansion'})\n",
    "                each_row['cordinate'] = (b.find(name='a',attrs={\"class\":\"external text\", \"rel\":\"nofollow\"}).find(name='span',attrs={'class':'geo-dec'}).text)\n",
    "                # end\n",
    "                \n",
    "                \n",
    "                #loc_href.append(loc.a['href'])\n",
    "                each_row['Deaths']=next(iter_).text.rstrip()\n",
    "                each_row['Injuries']=next(iter_).text.rstrip()\n",
    "                each_row['Description']=next(iter_).text.rstrip()\n",
    "            except StopIteration: \n",
    "                break\n",
    "            \n",
    "        data.append(each_row)\n",
    "        #print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_data.pkl','wb') as f:\n",
    "    pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data[1:])\n",
    "\n",
    "df = df.dropna(axis=0).reset_index(drop=True)\n",
    "\n",
    "df[['City','State']]=df.Location.str.split(',',expand=True)\n",
    "df.drop(columns=['Location'],inplace=True)\n",
    "\n",
    "df['Deaths'] = df.Deaths.str.extract(r'(\\d+)')\n",
    "df['Injuries'] = df.Injuries.str.extract(r'(\\d+)')\n",
    "\n",
    "\n",
    "df[['Latitude','Longitude']] = df.cordinate.str.split(' ',expand=True)\n",
    "df.drop(columns=['cordinate'],inplace =True)\n",
    "\n",
    "\n",
    "df['Latitude'] = df.Latitude.str.extract(r'(\\d+\\.\\d+)')\n",
    "df['Longitude'] = df.Longitude.str.extract(r'(\\d+\\.\\d+)')\n",
    "\n",
    "df['Longitude'] = df['Longitude'].apply(lambda x: '-'+x)\n",
    "\n",
    "df['Longitude']= df['Longitude'].astype(float)\n",
    "df['Latitude'] = df['Latitude'].astype(float)\n",
    "\n",
    "df['Date'] = df['Date'].apply(lambda x:datetime.strptime(x,'%B %d, %Y'))\n",
    "df['Description'] =df['Description'].str.replace(r'(\\[\\d+\\])*','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_data.pkl','wb') as f:\n",
    "    pickle.dump(df,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
